import { HttpClient } from '../core/client.ts';
import { ScanConfig, CrawledUrl, FormInfo } from '../core/types.ts';

export class Crawler {
    private client: HttpClient;
    private config: ScanConfig;
    private visited = new Set<string>();
    private queue: { url: string; depth: number }[] = [];

    constructor(client: HttpClient, config: ScanConfig) {
        this.client = client;
        this.config = config;
    }

    private normalizeUrl(url: string, base: string): string | null {
        try {
            const fullUrl = new URL(url, base);
            // Stay on same hostname
            if (fullUrl.hostname !== new URL(base).hostname) return null;
            // Skip static assets
            if (/\.(jpg|jpeg|png|gif|css|js|woff|woff2|ico|svg)$/i.test(fullUrl.pathname)) return null;
            return fullUrl.toString();
        } catch {
            return null;
        }
    }

    private extractLinks(html: string, base: string): string[] {
        const links: string[] = [];
        // Basic regex for href - sufficient for serverless constraint
        const hrefRegex = /href=["']([^"']+)["']/g;
        let match;
        while ((match = hrefRegex.exec(html)) !== null) {
            const normalized = this.normalizeUrl(match[1], base);
            if (normalized) links.push(normalized);
        }
        return links;
    }

    private extractForms(html: string, base: string): FormInfo[] {
        const forms: FormInfo[] = [];
        // Basic regex for forms - robust HTML parsing is heavy for Deno/Serverless
        const formRegex = /<form[^>]*action=["']([^"']*)["'][^>]*method=["']([^"']*)["'][^>]*>(.*?)<\/form>/gis;

        let match;
        while ((match = formRegex.exec(html)) !== null) {
            const action = this.normalizeUrl(match[1] || '', base) || base;
            const method = (match[2] || 'GET').toUpperCase();
            const content = match[3];

            const inputRegex = /<input[^>]*name=["']([^"']+)["'][^>]*type=["']([^"']*)["'][^>]*>/gi;
            const inputs: { name: string; type: string }[] = [];
            let inputMatch;
            while ((inputMatch = inputRegex.exec(content)) !== null) {
                inputs.push({ name: inputMatch[1], type: inputMatch[2] || 'text' });
            }

            if (inputs.length > 0) {
                forms.push({ action, method, inputs });
            }
        }
        return forms;
    }

    async crawl(startUrl: string): Promise<CrawledUrl[]> {
        this.queue.push({ url: startUrl, depth: 0 });
        this.visited.add(startUrl);
        const results: CrawledUrl[] = [];

        while (this.queue.length > 0 && results.length < this.config.maxPages) {
            const { url, depth } = this.queue.shift()!;

            try {
                console.log(`[Crawler] Visiting: ${url}`);
                const { response } = await this.client.get(url);
                const html = await response.text();

                const params = Array.from(new URL(url).searchParams.keys());
                const forms = this.extractForms(html, url);

                results.push({
                    url,
                    depth,
                    forms,
                    params,
                    method: 'GET'
                });

                if (depth < this.config.maxDepth) {
                    const links = this.extractLinks(html, url);
                    for (const link of links) {
                        if (!this.visited.has(link)) {
                            this.visited.add(link);
                            this.queue.push({ url: link, depth: depth + 1 });
                        }
                    }
                }
            } catch (e) {
                console.error(`[Crawler] Failed to visit ${url}: ${e}`);
            }
        }

        return results;
    }
}
